{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a9078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:07:54.685714: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 03:07:54.791762: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-17 03:07:55.234031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2023-02-17 03:07:55.234075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2023-02-17 03:07:55.234079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/bashlab/nur/test/venv/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/bashlab/nur/test/venv/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/bashlab/nur/test/venv/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/bashlab/nur/test/venv/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/bashlab/nur/test/venv/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/bashlab/nur/test/venv/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "#basic imports\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa    \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras import Sequential\n",
    "from keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers import Dense, Dropout, Input, Activation, LSTM\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.signal import butter, filtfilt, medfilt, lfilter, sosfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f2cddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 03:07:56.766204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:56.766430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:56.783093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:56.783330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:56.783501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:56.783686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:56.784673: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 03:07:56.786833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:56.787017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:56.787181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:57.158219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:57.158426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:57.158588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 03:07:57.158726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22291 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f3f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], btype='band', output='sos')\n",
    "    return sos\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = sosfilt(sos, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e33c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    \n",
    "    import numpy as np\n",
    "    from math import factorial\n",
    "    \n",
    "    try:\n",
    "        window_size = np.abs(int(window_size))\n",
    "        order = np.abs(int(order))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e39c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_processing\n",
    "\n",
    "path1 = './meditite/gpu_meditite/cohort_2_4/audio/'\n",
    "path2 = './meditite/gpu_meditite/cohort_2_4/cc/'\n",
    "\n",
    "test_id = [203, 204]\n",
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "for file1 in glob.glob(path1 +\"*.wav\"):\n",
    "    PID1 = int(file1[44:47])\n",
    "    try:\n",
    "        session1 = int(file1[49:51])\n",
    "        flag1 = 1\n",
    "    except:\n",
    "        session1 = int(file1[49])\n",
    "        flag1 = 0\n",
    "    if flag1 ==0:\n",
    "        try:\n",
    "            l1 = int(file1[52:54])\n",
    "        except:\n",
    "            l1 = int(file1[52])\n",
    "    else:\n",
    "        try:\n",
    "            l1 = int(file1[53:55])\n",
    "        except:\n",
    "            l1 = int(file1[53])\n",
    "\n",
    "        \n",
    "    for file2 in glob.glob(path2 + \"*.csv\"):\n",
    "\n",
    "        PID2 = int(file2[41:44])\n",
    "        try:\n",
    "            session2 = int(file2[46:48])\n",
    "            flag2 = 1\n",
    "        except:\n",
    "            session2 = int(file2[46])\n",
    "            flag2 = 0\n",
    "        \n",
    "        if flag2 ==0:\n",
    "            try:\n",
    "                l2 = int(file2[49:51])\n",
    "            except:\n",
    "                l2 = int(file2[49])\n",
    "        else:\n",
    "            try:\n",
    "                l2 = int(file2[50:52])\n",
    "            except:\n",
    "                l2 = int(file2[50])\n",
    "        if PID2 == PID1 and session2 == session1 and l2 == l1:\n",
    "            if PID2 in test_id:\n",
    "                if file1[-17:-4] == 'technic_audio':\n",
    "                    data, fs = librosa.load(file1, sr=11025)\n",
    "                    data = butter_bandpass_filter(data, 20, 1000, fs, order = 2)\n",
    "                    data = savitzky_golay(data, 101, 3)\n",
    "                    for i in range(0, len(data), int(fs*1)):\n",
    "                        data_chunk = data[i:int(i+fs*15)]\n",
    "                        if i+int(fs*15) >len(data):\n",
    "                            continue\n",
    "                        data_chunk = librosa.feature.mfcc(y = data_chunk, sr=fs, n_mfcc=40, n_fft = 512, win_length=512, hop_length = 256)\n",
    "                        \n",
    "                        test_data.append(data_chunk)\n",
    "                df = pd.read_csv(file2, index_col = 0)\n",
    "                label = df['breathing_rate'].values\n",
    "                for i in range(len(label)):\n",
    "                    if i+15 > len(label):\n",
    "                        break\n",
    "                    test_label.append(round(np.mean(label[i:i+15])))\n",
    "                    \n",
    "                \n",
    "            else:\n",
    "                if file1[-17:-4] == 'technic_audio':\n",
    "                    data, fs = librosa.load(file1, sr=11025)\n",
    "                    data = butter_bandpass_filter(data, 20, 1000, fs, order = 2)\n",
    "                    data = savitzky_golay(data, 101, 3)\n",
    "                    for i in range(0, len(data), int(fs*1)):\n",
    "                        data_chunk = data[i:int(i+fs*15)]\n",
    "                        if i+int(fs*15) >len(data):\n",
    "                            continue\n",
    "                        data_chunk = librosa.feature.mfcc(y = data_chunk, sr=fs, n_mfcc=40, n_fft = 512, win_length= 512, hop_length = 256)\n",
    "                        train_data.append(data_chunk)\n",
    "                df = pd.read_csv(file2, index_col = 0)\n",
    "                label = df['breathing_rate'].values\n",
    "                for i in range(len(label)):\n",
    "                    if i+15 > len(label):\n",
    "                        break\n",
    "                    train_label.append(round(np.mean(label[i:i+15])))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50cd4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data\n",
    "test_data = np.array(test_data)\n",
    "np.save('audio_br_test_data_mfcc.npy', test_data)\n",
    "del test_data\n",
    "np.save('audio_br_train_label_mfcc.npy', train_label)\n",
    "np.save('audio_br_test_label_mfcc.npy', test_label)\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "np.save('audio_br_train_data_mfcc.npy', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b7da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('audio_br_train_data_mfcc.npy')\n",
    "X_test = np.load('audio_br_test_data_mfcc.npy')\n",
    "\n",
    "y_train = np.load('audio_br_train_label_mfcc.npy')\n",
    "y_test = np.load('audio_br_test_label_mfcc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bba50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a36852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#netwrok_architecture\n",
    "inp = Input(shape=(X_train.shape[1:]))\n",
    "\n",
    "x = LSTM(32, return_sequences=False, stateful=False, dropout = 0.5)(inp)\n",
    "x = Dense(32)(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "out = Dense(1, activation = 'linear')(x)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce14910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath_co = 'log_mfcc_v2/br/'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath_co,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=1e-5)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdce588f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 02:57:13.354803: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3487573120 exceeds 10% of free system memory.\n",
      "2023-02-17 02:57:14.526163: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3487573120 exceeds 10% of free system memory.\n",
      "2023-02-17 02:57:17.059086: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2023-02-17 02:57:17.136803: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_mfcc_v2/br/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_mfcc_v2/br/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_mfcc_v2/br/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_mfcc_v2/br/assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='MSE',\n",
    "                optimizer=optimizer, metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=0, callbacks = [model_checkpoint_callback, early_stopping_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
